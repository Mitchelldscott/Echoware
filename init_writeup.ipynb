{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b4966da",
   "metadata": {},
   "source": [
    "# EchoWare\n",
    "\n",
    "Retarget an expert pose to an agent pose\n",
    "\n",
    "The expert and agent poses consist of a configuration space, set of links and a set of joint transforms.\n",
    "$\n",
    "    \\{\\mathbb{C}_e,\\mathbb{L}_e,\\mathbb{J}_e\\} \\rightarrow \\{\\mathbb{C}_a,\\mathbb{L}_a,\\mathbb{J}_a\\}\n",
    "$\n",
    "\n",
    "Where\n",
    "\n",
    "$ \\mathbb{C} $: Configuration, DOF x 1 vector \n",
    "\n",
    "$ \\mathbb{L} $: Link set, {(Polygon3D, &Joint, ...), ...} \n",
    "\n",
    "$ \\mathbb{J} $: Joint set, {(Translation3D, state, Axis3D, effect, &Link), ...}\n",
    "\n",
    "\n",
    "> **Configuration** of any robot can and should be implemented as a list of actuator states. This vector is the input to forward kinematics and the output of inverse kinematics.  \n",
    "\n",
    "> **Links** provide a geometric definition for the parts of a robot. A link consists of a polygon (convex hull of 3D points) and a possibly empty set of joint references.\n",
    "\n",
    "> **Joints** describe a state, axis and motion of the joint on the effected link. Most joints will be continuous revolute about their Z axis (standard way to define motor reference frames). Each joint refers to a single link, creating chains: link -> joint -> link -> joint -> link. The axis of the joint is a normal vector oriented along the axis of rotation (revolute) or linear motion (linear).\n",
    "\n",
    "For this project we will assume a set of rules the expert and agent must follow:\n",
    "- A Link can have any number of Joints\n",
    "- No set of links/joints forms a cycle\n",
    "- All chains end in a Link/Every joint has a base link and an effected link\n",
    "- A proper mapping should be independant of configuration\n",
    "\n",
    "\n",
    "## Example Definition\n",
    "![sample robot arm](two_link_basic.png)\n",
    "> 2 DOF, 3 link robot arm (joints at $P_1$ and $P_2$, ee at $P_3$)\n",
    "\n",
    "The above robot has the configuration space $$ \\begin{bmatrix}\\theta_1 \\\\ \\theta_2 \\end{bmatrix} $$\n",
    "\n",
    "The linkages can be defined as line segments connecting the two joints and end effector: $$ \\{ Link_0: ((P_0, P_1), Joint_1), Link_1: ((P_1, P_2), Joint_2),  Link_2: ((P_2, P_3), NULL)\\} $$\n",
    "*the points in this definition are defined in the link's reference frame. This means the first point in the segment is always at the origin and the second point is the length of the link along the X axis. The true orientation and position of the links is found using kinematics and requires knowledge of the joint states*\n",
    "\n",
    "The Joints are offset from the links by the line segment that defines the links. This allows a very simple Transform that translates by the vector difference of the end points (or the length of the link along the X axis). $$ \\{Joint_1: (P_1-P_0, \\theta_1, [0,0,1], revolute, Link_1), Joint_2: (P_2-P_1, \\theta_2, [0,0,1], revolute, Link_2)\\} $$\n",
    "\n",
    "### Forward Kinematics\n",
    "In order to solve the forward kinematics for the end effector, start with a vector from $Link_n$ to the end effector ($P_3-P_2$ in this case). Apply the effect of $Joint_n$ to this vector (rotation about Z) and add the transform to $Link_{n-1}$ ($P_2-P_1$), this is the end effector defined relative to $Link_{n-1}$. Repeat this process untill the end effector is defined about $Link_0$.\n",
    "\n",
    "## Retargeting Goals\n",
    "To retarget this pose we should consider what the goal of retargeting is. Ideally the agent can reproduce results of an expert's actions. Due to the complexity of considering the environment, this project simplifies the goal to imitating an expert's pose. Work done by students at CMU showed that imitating an experts pose well enough can lead to an agent accomplishing tasks. Future work should require an agent also diverge from the expert enough to be in a feasible pose. This addition would look like physical constraints for the retargeting (no self collisions, match COM/momentum/forces).\n",
    "\n",
    "## Retargeting Delivarables\n",
    "An efficient and easy to implement mapping that can represent the result of this algorithm is the matrix $ \\mathbb{M}_e^a $. Which is implemented as $ \\mathbb{C}_a = \\mathbb{M}_e^a * \\mathbb{C}_e $. This claims any joint on the agent is a linear combiniation of joints on the expert. Also note $ \\mathbb{M}_e^a \\in \\mathbb{R}^{n,m}$, where n is the agent DOF and m is the expert DOF (ie a cell relating each expert and agent joint). The algorithm below will descibe how to asssign weights to the cells of $ \\mathbb{M}_e^a $.\n",
    "\n",
    "\n",
    "## Joint/Link Matching\n",
    "*Joints with the same depth/transform will match* \n",
    "\n",
    "    // does not require kinematics or optimization\n",
    "    // uses thresholds and distances for similarities\n",
    "    // subject to biasing\n",
    "    match_joints(link_e, link_a, M):\n",
    "        \n",
    "        for joint_e in link_e:\n",
    "        \n",
    "            for joint_a in link_a:\n",
    "\n",
    "                // joint is defined with a similar orientation and translation\n",
    "                // always between 0 and 1, but thrown out if < joint threshold\n",
    "                let weight = joint_e ~= joint_a\n",
    "                \n",
    "                if weight > joint_threshold && link_e ~= link_a > link_threshold:\n",
    "\n",
    "                    M(joint_e, joint_a) = weight\n",
    "\n",
    "                    // match_joints(link_e, joint_a.link, M) // try adjacent links\n",
    "                    \n",
    "                    match_joints(joint_e.link, joint_a.link, M) // same depth links\n",
    "                    \n",
    "                    // match_joints(joint_e.link, link_a, M) // try adjacent links\n",
    "                    \n",
    "    M = zeros(n,m) // default weights of zero for all joint relationships\n",
    "    match_joints(expert_base, agent_base, M)\n",
    "                \n",
    "\n",
    "    \n",
    "Beginning from the expert's base link examine the 0 depth joints (connected to the base). Matching Joints are: the same depth, close in proximity (euclidean distance, orientation threashold, effect) relative to their parent link and have a similar effected link (inertia/vertices/faces?). An agent's joint can match with multiple joints on an expert (but not vise versa) resulting in a weighted average (this could get messy...). Continue matching joints at each depth (joints only match if their parents match).\n",
    "\n",
    "> if the expert chain has a different number of links, the agent will partially mimic that chain (maybe allow joints to relate to joints that are proportionally deep in the chain, underactuated maps => average of many, overactuated maps => one to many)\n",
    "\n",
    "### End Effector/Chain matching\n",
    "*Chains will match end effector positions* \\\n",
    "Begin with the expert's base link and match any joints (ignoring links). Then select from the following for each joint:\n",
    "1. Use IK of agent to create similar ee position (likely doesn't use the same shape)\n",
    "2. Use optimization to minimize the error in keypoints on the chain\n",
    "3. Use the closing circle (sphere) algorithm (put all joint positions and desired ee on a circle and shrink the circle until they meet)\n",
    "\n",
    "> Both require normalizing each chain definition so numerically chains have the same reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61a9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows file changes to be included without reloading the kernel\n",
    "# Still requires reimporting the modules\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cf664e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pose import Transform3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2ab1eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = Transform3D(1,0,0,1.57,-3.1415,1.57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c63e8fa-f351-4a95-98c1-7d068eb5fb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.66453526e-15, 3.41810697e-12, 7.37825283e-08])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([1 ,0 ,0])\n",
    "tf.transform(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc249f1a-ca7b-452f-bcda-083dd72615cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
